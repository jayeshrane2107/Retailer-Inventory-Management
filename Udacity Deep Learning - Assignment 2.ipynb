{
    "cells": [
        {
            "cell_type": "code", 
            "source": "# These are all the modules we'll be using later. Make sure you can import them\n# before proceeding further.\nfrom __future__ import print_function\nimport numpy as np\nimport tensorflow as tf\nfrom six.moves import cPickle as pickle\nfrom six.moves import range", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "execution_count": 39
        }, 
        {
            "cell_type": "code", 
            "source": "pickle_file = 'notMNIST.pickle'\n\nwith open(pickle_file, 'rb') as f:\n  save = pickle.load(f)\n  train_dataset = save['train_dataset']\n  train_labels = save['train_labels']\n  valid_dataset = save['valid_dataset']\n  valid_labels = save['valid_labels']\n  test_dataset = save['test_dataset']\n  test_labels = save['test_labels']\n  del save  # hint to help gc free up memory\n  print('Training set', train_dataset.shape, train_labels.shape)\n  print('Validation set', valid_dataset.shape, valid_labels.shape)\n  print('Test set', test_dataset.shape, test_labels.shape)", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "Training set (200000, 28, 28) (200000,)\nValidation set (10000, 28, 28) (10000,)\nTest set (10000, 28, 28) (10000,)\n", 
                    "name": "stdout"
                }
            ], 
            "execution_count": 40
        }, 
        {
            "cell_type": "code", 
            "source": "image_size = 28\nnum_labels = 10\n\ndef reformat(dataset, labels):\n  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n  # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n  return dataset, labels\ntrain_dataset, train_labels = reformat(train_dataset, train_labels)\nvalid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\ntest_dataset, test_labels = reformat(test_dataset, test_labels)\nprint('Training set', train_dataset.shape, train_labels.shape)\nprint('Validation set', valid_dataset.shape, valid_labels.shape)\nprint('Test set', test_dataset.shape, test_labels.shape)", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "Training set (200000, 784) (200000, 10)\nValidation set (10000, 784) (10000, 10)\nTest set (10000, 784) (10000, 10)\n", 
                    "name": "stdout"
                }
            ], 
            "execution_count": 41
        }, 
        {
            "cell_type": "code", 
            "source": "\n# With gradient descent training, even this much data is prohibitive.\n# Subset the training data for faster turnaround.\ntrain_subset = 10000\n\ngraph = tf.Graph()\nwith graph.as_default():\n\n  # Input data.\n  # Load the training, validation and test data into constants that are\n  # attached to the graph.\n  tf_train_dataset = tf.constant(train_dataset[:train_subset, :])\n  tf_train_labels = tf.constant(train_labels[:train_subset])\n  tf_valid_dataset = tf.constant(valid_dataset)\n  tf_test_dataset = tf.constant(test_dataset)\n  \n  # Variables.\n  # These are the parameters that we are going to be training. The weight\n  # matrix will be initialized using random values following a (truncated)\n  # normal distribution. The biases get initialized to zero.\n  weights = tf.Variable(\n    tf.truncated_normal([image_size * image_size, num_labels]))\n  biases = tf.Variable(tf.zeros([num_labels]))\n  \n  # Training computation.\n  # We multiply the inputs with the weight matrix, and add biases. We compute\n  # the softmax and cross-entropy (it's one operation in TensorFlow, because\n  # it's very common, and it can be optimized). We take the average of this\n  # cross-entropy across all training examples: that's our loss.\n  logits = tf.matmul(tf_train_dataset, weights) + biases\n  loss = tf.reduce_mean(\n    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n  \n  # Optimizer.\n  # We are going to find the minimum of this loss using gradient descent.\n  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n  \n  # Predictions for the training, validation, and test data.\n  # These are not part of training, but merely here so that we can report\n  # accuracy figures as we train.\n  train_prediction = tf.nn.softmax(logits)\n  valid_prediction = tf.nn.softmax(\n    tf.matmul(tf_valid_dataset, weights) + biases)\n  test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "execution_count": 42
        }, 
        {
            "cell_type": "code", 
            "source": "num_steps = 801\n\ndef accuracy(predictions, labels):\n  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n          / predictions.shape[0])\n\nwith tf.Session(graph=graph) as session:\n  # This is a one-time operation which ensures the parameters get initialized as\n  # we described in the graph: random weights for the matrix, zeros for the\n  # biases. \n  tf.global_variables_initializer().run()\n  print('Initialized')\n  for step in range(num_steps):\n    # Run the computations. We tell .run() that we want to run the optimizer,\n    # and get the loss value and the training predictions returned as numpy\n    # arrays.\n    _, l, predictions = session.run([optimizer, loss, train_prediction])\n    if (step % 100 == 0):\n      print('Loss at step %d: %f' % (step, l))\n      print('Training accuracy: %.1f%%' % accuracy(\n        predictions, train_labels[:train_subset, :]))\n      # Calling .eval() on valid_prediction is basically like calling run(), but\n      # just to get that one numpy array. Note that it recomputes all its graph\n      # dependencies.\n      print('Validation accuracy: %.1f%%' % accuracy(\n        valid_prediction.eval(), valid_labels))\n  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "Initialized\nLoss at step 0: 18.870695\nTraining accuracy: 6.9%\nValidation accuracy: 8.2%\nLoss at step 100: 2.318349\nTraining accuracy: 72.0%\nValidation accuracy: 70.0%\nLoss at step 200: 1.865926\nTraining accuracy: 75.0%\nValidation accuracy: 72.3%\nLoss at step 300: 1.619912\nTraining accuracy: 76.4%\nValidation accuracy: 73.3%\nLoss at step 400: 1.456444\nTraining accuracy: 77.2%\nValidation accuracy: 73.6%\nLoss at step 500: 1.336043\nTraining accuracy: 77.7%\nValidation accuracy: 73.9%\nLoss at step 600: 1.241799\nTraining accuracy: 78.0%\nValidation accuracy: 74.1%\nLoss at step 700: 1.165146\nTraining accuracy: 78.4%\nValidation accuracy: 74.2%\nLoss at step 800: 1.101124\nTraining accuracy: 78.9%\nValidation accuracy: 74.2%\nTest accuracy: 82.5%\n", 
                    "name": "stdout"
                }
            ], 
            "execution_count": 43
        }, 
        {
            "cell_type": "code", 
            "source": "batch_size = 128\n\ngraph = tf.Graph()\nwith graph.as_default():\n\n  # Input data. For the training data, we use a placeholder that will be fed\n  # at run time with a training minibatch.\n  tf_train_dataset = tf.placeholder(tf.float32,\n                                    shape=(batch_size, image_size * image_size))\n  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n  tf_valid_dataset = tf.constant(valid_dataset)\n  tf_test_dataset = tf.constant(test_dataset)\n  \n  # Variables.\n  weights = tf.Variable(\n    tf.truncated_normal([image_size * image_size, num_labels]))\n  biases = tf.Variable(tf.zeros([num_labels]))\n  \n  # Training computation.\n  logits = tf.matmul(tf_train_dataset, weights) + biases\n  loss = tf.reduce_mean(\n    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n  \n  # Optimizer.\n  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n  \n  # Predictions for the training, validation, and test data.\n  train_prediction = tf.nn.softmax(logits)\n  valid_prediction = tf.nn.softmax(\n    tf.matmul(tf_valid_dataset, weights) + biases)\n  test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "execution_count": 44
        }, 
        {
            "cell_type": "code", 
            "source": "\nnum_steps = 3001\n\nwith tf.Session(graph=graph) as session:\n  tf.global_variables_initializer().run()\n  print(\"Initialized\")\n  for step in range(num_steps):\n    # Pick an offset within the training data, which has been randomized.\n    # Note: we could use better randomization across epochs.\n    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n    # Generate a minibatch.\n    batch_data = train_dataset[offset:(offset + batch_size), :]\n    batch_labels = train_labels[offset:(offset + batch_size), :]\n    # Prepare a dictionary telling the session where to feed the minibatch.\n    # The key of the dictionary is the placeholder node of the graph to be fed,\n    # and the value is the numpy array to feed to it.\n    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n    _, l, predictions = session.run(\n      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n    if (step % 500 == 0):\n      print(\"Minibatch loss at step %d: %f\" % (step, l))\n      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n      print(\"Validation accuracy: %.1f%%\" % accuracy(\n        valid_prediction.eval(), valid_labels))\n  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "Initialized\nMinibatch loss at step 0: 15.855091\nMinibatch accuracy: 7.8%\nValidation accuracy: 10.1%\nMinibatch loss at step 500: 1.713185\nMinibatch accuracy: 71.9%\nValidation accuracy: 75.3%\nMinibatch loss at step 1000: 1.278759\nMinibatch accuracy: 70.3%\nValidation accuracy: 76.7%\nMinibatch loss at step 1500: 1.322669\nMinibatch accuracy: 75.8%\nValidation accuracy: 77.3%\nMinibatch loss at step 2000: 0.748910\nMinibatch accuracy: 81.2%\nValidation accuracy: 78.0%\nMinibatch loss at step 2500: 0.599041\nMinibatch accuracy: 85.9%\nValidation accuracy: 78.3%\nMinibatch loss at step 3000: 0.680260\nMinibatch accuracy: 81.2%\nValidation accuracy: 78.3%\nTest accuracy: 85.5%\n", 
                    "name": "stdout"
                }
            ], 
            "execution_count": 45
        }, 
        {
            "cell_type": "code", 
            "source": "batch_size = 128\nhidden_layer_size = 1024\n\ngraph = tf.Graph()\nwith graph.as_default():\n    tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size,image_size*image_size))\n    tf_train_labels = tf.placeholder(tf.float32,shape=(batch_size,num_labels))\n    tf_valid_dataset = tf.constant(valid_dataset)\n    tf_test_dataset = tf.constant(test_dataset)\n    \n    weights_hidden = tf.Variable(tf.truncated_normal([image_size*image_size,hidden_layer_size]))\n    bias_hidden = tf.Variable(tf.zeros([hidden_layer_size]))\n    hidden = tf.nn.relu(tf.matmul(tf_train_dataset,weights_hidden)+bias_hidden)\n    \n    weights_output = tf.Variable(tf.truncated_normal([hidden_layer_size,num_labels]))\n    bias_output = tf.Variable(tf.zeros([num_labels]))\n    logits = tf.matmul(hidden,weights_output)+bias_output\n    \n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=tf_train_labels))\n    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n    \n    train_prediction = tf.nn.softmax(logits)\n    \n    hidden_validation = tf.nn.relu(tf.matmul(tf_valid_dataset,weights_hidden)+bias_hidden)\n    valid_prediction = tf.nn.softmax(tf.matmul(hidden_validation,weights_output)+bias_output)\n    \n    hidden_test = tf.nn.relu(tf.matmul(tf_test_dataset,weights_hidden)+bias_hidden)\n    test_prediction = tf.nn.softmax(tf.matmul(hidden_test,weights_output)+bias_output)", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 46
        }, 
        {
            "cell_type": "code", 
            "source": "num_steps=3001\n\ndef accuracy(predictions,labels):\n    return (100*np.sum(np.argmax(predictions,1)==np.argmax(labels,1))/predictions.shape[0])\n\nwith tf.Session(graph=graph) as session:\n    tf.global_variables_initializer().run()\n    print(\"Initialized\")\n    for step in range(num_steps):\n        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n        batch_data = train_dataset[offset:offset+batch_size,:]\n        batch_labels = train_labels[offset:offset+batch_size,:]\n        feed_dict = {tf_train_dataset:batch_data, tf_train_labels:batch_labels}\n        _,l , predictions = session.run([optimizer,loss,train_prediction],feed_dict=feed_dict)\n        if (step % 500 == 0):\n            print(\"Minibatch loss at step %d: %f\" % (step, l))\n            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n            print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(),valid_labels))\n    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "Initialized\nMinibatch loss at step 0: 360.354736\nMinibatch accuracy: 10.2%\nValidation accuracy: 38.9%\nMinibatch loss at step 500: 9.874890\nMinibatch accuracy: 78.9%\nValidation accuracy: 79.0%\nMinibatch loss at step 1000: 6.892537\nMinibatch accuracy: 80.5%\nValidation accuracy: 81.0%\nMinibatch loss at step 1500: 5.047996\nMinibatch accuracy: 80.5%\nValidation accuracy: 80.8%\nMinibatch loss at step 2000: 7.420320\nMinibatch accuracy: 81.2%\nValidation accuracy: 82.2%\nMinibatch loss at step 2500: 2.730374\nMinibatch accuracy: 85.9%\nValidation accuracy: 81.7%\nMinibatch loss at step 3000: 3.905237\nMinibatch accuracy: 85.9%\nValidation accuracy: 82.1%\nTest accuracy: 88.6%\n", 
                    "name": "stdout"
                }
            ], 
            "execution_count": 47
        }
    ], 
    "nbformat": 4, 
    "metadata": {
        "kernelspec": {
            "language": "python", 
            "name": "python3-spark21", 
            "display_name": "Python 3.5 (Experimental) with Spark 2.1"
        }, 
        "language_info": {
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }, 
            "pygments_lexer": "ipython3", 
            "version": "3.5.2", 
            "nbconvert_exporter": "python", 
            "mimetype": "text/x-python", 
            "name": "python"
        }
    }, 
    "nbformat_minor": 1
}